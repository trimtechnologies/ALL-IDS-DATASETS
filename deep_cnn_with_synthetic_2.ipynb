{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_cnn_with_synthetic_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trimtechnologies/ALL-IDS-DATASETS/blob/main/deep_cnn_with_synthetic_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmv8QxtzF7F4"
      },
      "outputs": [],
      "source": [
        "!pip install imblearn\n",
        "!pip install torch\n",
        "!pip install pytorch-tabnet\n",
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "import collections\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import BorderlineSMOTE \n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#from sklearn import tree\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#from sklearn.ensemble import AdaBoostClassifier\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "TKMn24obKBw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QP6-ql2e4lOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"/content/drive/MyDrive/2017_Dataset/Multi-Class/all_data_merged_attacks.csv\"\n",
        "read = pd.read_csv(data)\n",
        "df = read.iloc[:,:]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "8EpSc5F9KDzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.info()"
      ],
      "metadata": {
        "id": "FS7QYUDGNhLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.columns"
      ],
      "metadata": {
        "id": "ogOSjwBoZYWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df.iloc[:,:76])\n",
        "\n",
        "#scaler = MinMaxScaler()\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "\n",
        "X = scaler.fit_transform(df[['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
        "       'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
        "       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
        "       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
        "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
        "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
        "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
        "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
        "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
        "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
        "       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
        "       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
        "       'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
        "       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
        "       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
        "       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
        "       'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
        "       'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n",
        "       'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate',\n",
        "       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n",
        "       'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
        "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
        "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
        "       'Idle Std', 'Idle Max', 'Idle Min']])\n",
        "\n",
        "#X =  normalize(df.iloc[:,:76])\n",
        "print(X.shape)\n",
        "y = df['Label']\n",
        "print(y.shape)\n",
        "\n",
        "y = LabelEncoder().fit_transform(y)"
      ],
      "metadata": {
        "id": "IK2WXGAONIcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(collections.Counter(y))"
      ],
      "metadata": {
        "id": "8bO6iOGdP2ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = {0: 2359289, 4: 252661, 7: 252661, 3: 252661, 2: 252661, 8: 252661, 1: 252661, 6: 252661, 5: 252661}\n",
        "#{1: 2359289, 0: 1132298}\n",
        "#{1: 1651502, 0: 792608}\n",
        "#smt = SMOTE(sampling_strategy=strategy, k_neighbors=5, random_state=42)\n",
        "#X, y = smt.fit_resample(X, y)\n",
        "\n",
        "#strategy_tl = {0: 252661, 4: 252661, 7: 252661, 3: 252661, 2: 252661, 8: 252661, 1: 252661, 6: 252661, 5: 252661}\n",
        "rus = RandomUnderSampler(sampling_strategy='not minority',random_state=42)\n",
        "X, y = rus.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "CKO0nThUVw2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(collections.Counter(y))\n"
      ],
      "metadata": {
        "id": "4Eu5LAtzmcva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state=42, stratify=y)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size = 0.5, random_state=42, stratify=y_test)\n",
        "\n",
        "a = np.array(y_train)\n",
        "b = np.zeros((a.size, a.max()+1))\n",
        "b[np.arange(a.size),a] = 1\n",
        "y_train = b\n",
        "print(y_train.shape)\n",
        "\n",
        "a = np.array(y_test)\n",
        "b = np.zeros((a.size, a.max()+1))\n",
        "b[np.arange(a.size),a] = 1\n",
        "y_test = b\n",
        "print(y_test.shape)\n",
        "\n",
        "a = np.array(y_val)\n",
        "b = np.zeros((a.size, a.max()+1))\n",
        "b[np.arange(a.size),a] = 1\n",
        "y_val = b\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "id": "X7AQ1DoU4keb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape the data for CNN\n",
        "X_train = X_train.reshape(len(X_train), X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(len(X_test), X_test.shape[1], 1)\n",
        "X_val = X_val.reshape(len(X_val), X_val.shape[1], 1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)"
      ],
      "metadata": {
        "id": "azGBap5uXPQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu',input_shape=(76,1)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(9, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, verbose=0)\n",
        "\n",
        "#KerasClassifier(build_fn=model, epochs=200, batch_size=5, verbose=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "4AlgwDZpevaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(X_test, y_test)\n",
        "print((accuracy*100))"
      ],
      "metadata": {
        "id": "DtNxSG0JwJ-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "i0ZC7duEB5VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_class = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "id": "okEegceQCqfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test_class, y_pred, digits=6))"
      ],
      "metadata": {
        "id": "BaULM3K8CJwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "ConfusionMatrixDisplay.from_predictions(y_test_class, y_pred).plot()"
      ],
      "metadata": {
        "id": "WGRSLHVwCZj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pb2N0mQvEdtE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}